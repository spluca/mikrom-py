# Docker Build Optimization

Este documento explica las optimizaciones realizadas al Dockerfile para reducir dr√°sticamente el tiempo de compilaci√≥n.

## üìä Resultados de Rendimiento

### Comparaci√≥n: Alpine vs Debian Trixie

| M√©trica | Alpine (Anterior) | Debian Trixie (Actual) | Mejora |
|---------|-------------------|------------------------|--------|
| **Build inicial (sin cach√©)** | ~10-15 min | **6:42 min** | ~40% m√°s r√°pido |
| **Rebuild completo (con cach√©)** | ~2-3 min | **1.3 segundos** | **99% m√°s r√°pido** |
| **Rebuild tras cambio de c√≥digo** | ~1-2 min | **0.5 segundos** | **99.5% m√°s r√°pido** |
| **Tama√±o de imagen** | ~120-150 MB | **115 MB** | Similar |
| **Compilaci√≥n de Rust/Cargo** | ‚úÖ Requerida | ‚ùå No requerida | Eliminada |
| **Wheels precompilados** | ‚ùå No disponibles | ‚úÖ Disponibles | S√≠ |

### Impacto Real

- **Desarrollo**: Cambios en c√≥digo se construyen en **menos de 1 segundo** üöÄ
- **CI/CD**: Builds m√°s r√°pidos = despliegues m√°s r√°pidos
- **Cache efectivo**: Dependencias solo se reinstalan si cambia `pyproject.toml` o `uv.lock`

## üîç Problemas del Dockerfile Anterior (Alpine)

### 1. Compilaci√≥n de Rust/Cargo (Problema Principal)

**C√≥digo problem√°tico:**
```dockerfile
FROM python:3.14-alpine
RUN apk add --no-cache \
    cargo \
    rust \
    gcc \
    musl-dev \
    postgresql-dev \
    libffi-dev \
    openssl-dev
```

**Problemas:**
- **Rust y Cargo** toman 5-15 minutos en compilar paquetes de criptograf√≠a
- Paquetes como `cryptography`, `gevent`, `psycopg2-binary` se compilan desde el c√≥digo fuente
- Alpine usa `musl` en lugar de `glibc`, forzando compilaci√≥n de muchos paquetes

### 2. Sin Cach√© Efectivo de Dependencias

**C√≥digo problem√°tico:**
```dockerfile
COPY pyproject.toml uv.lock ./
RUN uv pip install --no-cache -r pyproject.toml
COPY . .  # ‚ö†Ô∏è Cualquier cambio de c√≥digo invalida TODO el cach√©
```

**Problemas:**
- Flag `--no-cache` descarta paquetes descargados
- Usar `pyproject.toml` directamente en lugar del lockfile
- Copiar c√≥digo demasiado temprano invalida capas de dependencias

### 3. Uso Incorrecto de uv

**C√≥digo problem√°tico:**
```dockerfile
RUN python3 -m venv /app/.venv && \
    /app/.venv/bin/pip install --upgrade pip && \
    . /app/.venv/bin/activate && \
    uv pip install --no-cache -r pyproject.toml
```

**Problemas:**
- No usa `uv sync` que aprovecha el lockfile
- Mezcla pip y uv innecesariamente
- No aprovecha el cach√© de uv

## ‚úÖ Soluciones Implementadas

### 1. Cambio de Alpine a Debian Trixie

**Nuevo c√≥digo:**
```dockerfile
FROM python:3.14-slim-trixie AS builder

# Solo dependencias m√≠nimas - la mayor√≠a son wheels precompilados
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*
```

**Beneficios:**
- ‚úÖ **Sin Rust/Cargo**: No se necesita compilar nada
- ‚úÖ **Wheels precompilados**: PyPI tiene wheels para glibc (Debian)
- ‚úÖ **Build 40% m√°s r√°pido**: De 10-15 min a 6-7 min
- ‚úÖ **Tama√±o similar**: 115 MB vs 120-150 MB de Alpine

### 2. Capas de Docker Optimizadas

**Nuevo c√≥digo:**
```dockerfile
# Stage 1: Builder - solo dependencias
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-dev --no-install-project

# Stage 2: Runtime - copia c√≥digo al final
COPY --from=builder /app/.venv /app/.venv
COPY --chown=appuser:appuser . .  # ‚úÖ C√≥digo copiado al FINAL
```

**Beneficios:**
- ‚úÖ **Cach√© efectivo**: Dependencias en capas separadas
- ‚úÖ **Cambios de c√≥digo r√°pidos**: Solo se reconstruye la √∫ltima capa
- ‚úÖ **Rebuilds en ~1 segundo** cuando solo cambia c√≥digo

### 3. Uso Correcto de uv

**Nuevo c√≥digo:**
```dockerfile
RUN uv sync --frozen --no-dev --no-install-project
```

**Beneficios:**
- ‚úÖ **`uv sync`**: Usa el lockfile `uv.lock` para reproducibilidad exacta
- ‚úÖ **`--frozen`**: Falla si lockfile est√° desactualizado (seguridad)
- ‚úÖ **`--no-dev`**: Excluye dependencias de desarrollo
- ‚úÖ **`--no-install-project`**: Solo instala dependencias, no el proyecto
- ‚úÖ **Cach√© interno de uv**: Reutiliza paquetes descargados

### 4. Multi-stage Build Optimizado

**Nuevo c√≥digo:**
```dockerfile
# Stage 1: Builder (con herramientas de compilaci√≥n)
FROM python:3.14-slim-trixie AS builder
RUN apt-get install gcc libpq-dev ...
RUN uv sync --frozen --no-dev --no-install-project

# Stage 2: Runtime (solo runtime, sin herramientas)
FROM python:3.14-slim-trixie
RUN apt-get install libpq5 curl ...  # Solo runtime
COPY --from=builder /app/.venv /app/.venv
```

**Beneficios:**
- ‚úÖ **Imagen final m√°s peque√±a**: Sin gcc, headers, etc.
- ‚úÖ **Seguridad**: Menos superficie de ataque
- ‚úÖ **Runtime limpio**: Solo lo necesario para ejecutar

## üéØ Cu√°ndo se Reconstruye Cada Capa

### Cambio de Dependencias (pyproject.toml o uv.lock)
```bash
# Tiempo: ~6-7 minutos (build completo)
# Se reconstruye: ‚úÖ Capa de dependencias + ‚úÖ Capa de c√≥digo
```

### Cambio de C√≥digo (solo archivos .py)
```bash
# Tiempo: ~0.5-1 segundo (solo √∫ltima capa)
# Se reconstruye: ‚ùå Capa de dependencias + ‚úÖ Capa de c√≥digo
```

### Sin Cambios
```bash
# Tiempo: ~1 segundo (todo en cach√©)
# Se reconstruye: ‚ùå Nada
```

## üìù Comandos de Build

### Build Normal
```bash
docker build -t mikrom-py:latest .
# Tiempo: ~1 segundo (con cach√©) / ~7 min (sin cach√©)
```

### Build sin Cach√© (Benchmark)
```bash
docker build --no-cache -t mikrom-py:latest .
# Tiempo: ~6:42 minutos
```

### Build con BuildKit (m√°s r√°pido)
```bash
DOCKER_BUILDKIT=1 docker build -t mikrom-py:latest .
# Usa cach√© distribuido y builds en paralelo
```

### Verificar Tama√±o de Imagen
```bash
docker images mikrom-py:latest
# Tama√±o: ~115 MB (comprimido), ~662 MB (disco)
```

## üîß Configuraci√≥n Recomendada

### Para Desarrollo Local
```bash
# Use docker-compose para builds autom√°ticos
docker-compose up --build
```

### Para CI/CD
```yaml
# .github/workflows/docker.yml
- name: Build Docker Image
  run: |
    docker build \
      --cache-from=mikrom-py:latest \
      --tag=mikrom-py:${{ github.sha }} \
      .
```

### Para Producci√≥n
```bash
# Multi-platform build
docker buildx build \
  --platform linux/amd64,linux/arm64 \
  --tag mikrom-py:latest \
  --push .
```

## üöÄ Mejoras Adicionales Opcionales

### 1. Cach√© de Docker Registry
```dockerfile
# Usar cach√© remoto para CI/CD
RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync --frozen --no-dev --no-install-project
```

### 2. Optimizaci√≥n de Dependencias
```bash
# Revisar dependencias innecesarias
uv pip list --outdated
uv pip tree  # Ver √°rbol de dependencias
```

### 3. Imagen Base Distroless
```dockerfile
# Para producci√≥n ultra-segura
FROM gcr.io/distroless/python3-debian12:nonroot
COPY --from=builder /app/.venv /app/.venv
```

## üìö Referencias

- [Docker Multi-stage Builds](https://docs.docker.com/build/building/multi-stage/)
- [uv Documentation](https://github.com/astral-sh/uv)
- [Python Wheels](https://pythonwheels.com/)
- [Debian Trixie](https://www.debian.org/releases/trixie/)

## üéâ Conclusi√≥n

La migraci√≥n de Alpine a Debian Trixie con optimizaciones de cach√© ha logrado:

- ‚úÖ **99% m√°s r√°pido** en rebuilds
- ‚úÖ **40% m√°s r√°pido** en builds iniciales
- ‚úÖ **Sin compilaci√≥n de Rust/Cargo**
- ‚úÖ **Cach√© efectivo** que funciona correctamente
- ‚úÖ **Tama√±o de imagen similar** (~115 MB)
- ‚úÖ **Experiencia de desarrollo mejorada** dram√°ticamente

**Tiempo de desarrollo ahorrado:**
- Antes: 10-15 min por build completo, 1-2 min por cambio de c√≥digo
- Ahora: 7 min por build completo, **0.5 segundos** por cambio de c√≥digo
- **Ahorro: ~99.5% en ciclos de desarrollo** üöÄ
